{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74kSFbbO48Qz",
        "outputId": "2c9d862e-54ea-4211-a88d-f92ac189f2d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating public/private rsa key pair.\n",
            "Enter file in which to save the key (/root/.ssh/id_rsa): \n",
            "Enter passphrase (empty for no passphrase): \n",
            "Enter same passphrase again: \n",
            "Your identification has been saved in /root/.ssh/id_rsa.\n",
            "Your public key has been saved in /root/.ssh/id_rsa.pub.\n",
            "The key fingerprint is:\n",
            "SHA256:cyIohzuLhWYe/brkK8nPPiymBxet3pb0L2pW2D9o/0M root@e99b09091ee4\n",
            "The key's randomart image is:\n",
            "+---[RSA 4096]----+\n",
            "|                 |\n",
            "|                 |\n",
            "|   .             |\n",
            "|  ....           |\n",
            "|  oooo. S .      |\n",
            "|..++o o. +E      |\n",
            "|oB*= + o .       |\n",
            "|+OB=B = o .      |\n",
            "|=o*%*+ +oo..     |\n",
            "+----[SHA256]-----+\n"
          ]
        }
      ],
      "source": [
        "!ssh-keygen -t rsa -b 4096"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1Hu1UOk48NV",
        "outputId": "daf645e9-410a-4458-bf68-10de42647805"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "# github.com:22 SSH-2.0-babeld-fc31accb\n"
          ]
        }
      ],
      "source": [
        "!ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVk8OlDF48JE",
        "outputId": "e2d58017-e68b-4855-89d8-e4c3d68a6eae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQDxZ/EDutXfhi8U/fQhLmWkXe9d8+ik0/jGV3KyWoKmz5cCyYrJ71ZSpI27ej7Uu38wWYrj0wRWbOSP9Ib3rpR/3otknHNoTys9RKSMrtlHcJpkj/VcLyid5a0LwqFNETNr4D9FK/5+hDTAaNCxtH36PuKEeEe1SSL1mm1xoT036hIDmQQiYeZE+9CxWJIOdx0x/I0W6T5hvF2tkFeFrKNx020FiH6slrRJNqwgwsmwlcygPiknAm1mwzTi0nszsYaMA7Qs/cNl85E8kalJQBNehj+Ibhqdh1UDbum7++y9CDdBZHHTN1ODmGPaaaJ9JO3CnrrMrDxO5pL0Hro+91BUlCgXlzWaZOCjnGbmezKqIXoLyUQWWpvr9PIThMkCSkcIv/XGC9lmIB21eCwTb8tEtKHelgkEjEYLhtyWDz2R3PJ/gBUG7lLfxTBaKzYCSLKpE5fHQJnQKN1AByLWzfCaDyhOxGeRYmAbn3DJGD7g6irjvrnZC1M1DRSa9yiINwN5AocC1aD5geUr8JTyz4p7Qr2DEiJmiG0mSjoL9QA48mQELy8afKi/q9lMyDURfx92UeSJJZTWQ8Mdl6p0czQt5LFOvrGNdrJN4xCmTAPJeBpwunIjHexHqXLtl1sZHwXRF5n0xtDC3llMA8zci2SEX9Fci2/qSyqJZoqyAV+zFw== root@e99b09091ee4\n"
          ]
        }
      ],
      "source": [
        "!cat /root/.ssh/id_rsa.pub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIu1GPde48CT",
        "outputId": "994f6cfc-2708-471f-a9e0-8b4df4eb20da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Permanently added the RSA host key for IP address '192.30.255.112' to the list of known hosts.\r\n",
            "Hi JulianHerreilers! You've successfully authenticated, but GitHub does not provide shell access.\n"
          ]
        }
      ],
      "source": [
        "!ssh -T git@github.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgc-Zdgn475s"
      },
      "outputs": [],
      "source": [
        "!git config --global user.email \"jherreilers@gmail.com\"\n",
        "!git config --global user.name \"JulianColab\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZF5vlkJ5Ksx",
        "outputId": "af8b4305-dfa3-4527-ba51-c7c17746373f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'spraaksame-pantoffel'...\n",
            "remote: Enumerating objects: 7801, done.\u001b[K\n",
            "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 7801 (delta 17), reused 40 (delta 16), pack-reused 7758\u001b[K\n",
            "Receiving objects: 100% (7801/7801), 1.31 GiB | 20.93 MiB/s, done.\n",
            "Resolving deltas: 100% (85/85), done.\n",
            "Checking out files: 100% (2791/2791), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone git@github.com:JulianHerreilers/spraaksame-pantoffel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Yq9VSSn9stH",
        "outputId": "0abab14a-693f-4181-b297-af31bcfa8512"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Aug 17 09:38:39 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSQL-kkr9yA3",
        "outputId": "4a6c184a-d9e1-46ce-c446-5ae5f32d41c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HpeMY5rVFmP",
        "outputId": "be76c6ba-7b3c-4ee1-c2b0-c21c02ebadf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 79 kB 4.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 42.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 117 kB 74.8 MB/s \n",
            "\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 183 kB 7.7 MB/s \n",
            "\u001b[?25h  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 910 kB 7.4 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q omegaconf\n",
        "!pip install -q librosa==0.8.0\n",
        "!pip install -q univoc\n",
        "!pip install -q tacotron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np1LOqiUbGUe",
        "outputId": "8710a6c8-b4fd-41d0-8808-602bb45c3c78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyloudnorm\n",
            "  Downloading pyloudnorm-0.1.0-py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.7/dist-packages (from pyloudnorm) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from pyloudnorm) (1.7.3)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from pyloudnorm) (0.16.0)\n",
            "Installing collected packages: pyloudnorm\n",
            "Successfully installed pyloudnorm-0.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyloudnorm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjAyzlBUfSTA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import soundfile as sf\n",
        "from univoc import Vocoder\n",
        "from tacotron import load_cmudict, text_to_id, Tacotron\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio\n",
        "import pyloudnorm as pyln"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtYR_9LZww5v",
        "outputId": "c878e6e1-a295-4aa6-f4e8-9471ed488e6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/spraaksame-pantoffel\n",
            "afrza  datasets       rcrl_apd.1.4.1.txt  test.py\n",
            "afrZA  preprocess.py  tacotron\t\t  train.py\n"
          ]
        }
      ],
      "source": [
        "%cd spraaksame-pantoffel/\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELsJRx6sdDde",
        "outputId": "0279d681-2276-4c89-87c7-d99cef8cee0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting features for train set\n",
            "Wrote 2400 utterances, 794633 frames (2.76 hours)\n"
          ]
        }
      ],
      "source": [
        "!python preprocess.py afrZA datasets/afrZA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-VIuZYGadpm",
        "outputId": "802efadb-8e34-4172-e8de-d744e4722324"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading checkpoint from afrza/model-20000.pt\n",
            "100% 37/37 [00:58<00:00,  1.58s/it]\n",
            "epoch 541 : loss 0.0467 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.37s/it]\n",
            "epoch 542 : loss 0.0466 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.37s/it]\n",
            "epoch 543 : loss 0.0464 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.38s/it]\n",
            "epoch 544 : loss 0.0464 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.37s/it]\n",
            "epoch 545 : loss 0.0465 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.38s/it]\n",
            "epoch 546 : loss 0.0466 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.38s/it]\n",
            "epoch 547 : loss 0.0465 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.40s/it]\n",
            "epoch 548 : loss 0.0456 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.37s/it]\n",
            "epoch 549 : loss 0.0459 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.38s/it]\n",
            "epoch 550 : loss 0.0460 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.38s/it]\n",
            "epoch 551 : loss 0.0457 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.39s/it]\n",
            "epoch 552 : loss 0.0457 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.37s/it]\n",
            "epoch 553 : loss 0.0466 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.38s/it]\n",
            "epoch 554 : loss 0.0461 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.38s/it]\n",
            "epoch 555 : loss 0.0461 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.37s/it]\n",
            "epoch 556 : loss 0.0463 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.38s/it]\n",
            "epoch 557 : loss 0.0458 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.40s/it]\n",
            "epoch 558 : loss 0.0455 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.36s/it]\n",
            "epoch 559 : loss 0.0460 : [0.0005]\n",
            "100% 37/37 [00:49<00:00,  1.35s/it]\n",
            "epoch 560 : loss 0.0462 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.38s/it]\n",
            "epoch 561 : loss 0.0462 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.39s/it]\n",
            "epoch 562 : loss 0.0459 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.36s/it]\n",
            "epoch 563 : loss 0.0459 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.37s/it]\n",
            "epoch 564 : loss 0.0461 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.38s/it]\n",
            "epoch 565 : loss 0.0459 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.38s/it]\n",
            "epoch 566 : loss 0.0458 : [0.0005]\n",
            "100% 37/37 [00:52<00:00,  1.42s/it]\n",
            "epoch 567 : loss 0.0459 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.40s/it]\n",
            "epoch 568 : loss 0.0456 : [0.0005]\n",
            "100% 37/37 [00:52<00:00,  1.42s/it]\n",
            "epoch 569 : loss 0.0456 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.40s/it]\n",
            "epoch 570 : loss 0.0456 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.38s/it]\n",
            "epoch 571 : loss 0.0458 : [0.0005]\n",
            "100% 37/37 [00:52<00:00,  1.42s/it]\n",
            "epoch 572 : loss 0.0456 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.39s/it]\n",
            "epoch 573 : loss 0.0455 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.38s/it]\n",
            "epoch 574 : loss 0.0459 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.36s/it]\n",
            "epoch 575 : loss 0.0461 : [0.0005]\n",
            "100% 37/37 [00:52<00:00,  1.41s/it]\n",
            "epoch 576 : loss 0.0454 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.38s/it]\n",
            "epoch 577 : loss 0.0457 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.39s/it]\n",
            "epoch 578 : loss 0.0456 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.39s/it]\n",
            "epoch 579 : loss 0.0457 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.37s/it]\n",
            "epoch 580 : loss 0.0457 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.39s/it]\n",
            "epoch 581 : loss 0.0454 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.39s/it]\n",
            "epoch 582 : loss 0.0454 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.37s/it]\n",
            "epoch 583 : loss 0.0458 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.39s/it]\n",
            "epoch 584 : loss 0.0457 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.40s/it]\n",
            "epoch 585 : loss 0.0455 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.40s/it]\n",
            "epoch 586 : loss 0.0453 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.38s/it]\n",
            "epoch 587 : loss 0.0459 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.37s/it]\n",
            "epoch 588 : loss 0.0459 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.40s/it]\n",
            "epoch 589 : loss 0.0456 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.39s/it]\n",
            "epoch 590 : loss 0.0456 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.38s/it]\n",
            "epoch 591 : loss 0.0459 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.40s/it]\n",
            "epoch 592 : loss 0.0456 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.38s/it]\n",
            "epoch 593 : loss 0.0461 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.37s/it]\n",
            "epoch 594 : loss 0.0459 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.39s/it]\n",
            "epoch 595 : loss 0.0457 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.39s/it]\n",
            "epoch 596 : loss 0.0458 : [0.0005]\n",
            "100% 37/37 [00:52<00:00,  1.41s/it]\n",
            "epoch 597 : loss 0.0454 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.38s/it]\n",
            "epoch 598 : loss 0.0456 : [0.0005]\n",
            "100% 37/37 [00:52<00:00,  1.41s/it]\n",
            "epoch 599 : loss 0.0452 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.40s/it]\n",
            "epoch 600 : loss 0.0455 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.37s/it]\n",
            "epoch 601 : loss 0.0462 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.37s/it]\n",
            "epoch 602 : loss 0.0458 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.38s/it]\n",
            "epoch 603 : loss 0.0458 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.37s/it]\n",
            "epoch 604 : loss 0.0456 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.37s/it]\n",
            "epoch 605 : loss 0.0456 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.40s/it]\n",
            "epoch 606 : loss 0.0455 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.39s/it]\n",
            "epoch 607 : loss 0.0453 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.40s/it]\n",
            "epoch 608 : loss 0.0452 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.37s/it]\n",
            "epoch 609 : loss 0.0455 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.40s/it]\n",
            "epoch 610 : loss 0.0452 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.40s/it]\n",
            "epoch 611 : loss 0.0453 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.38s/it]\n",
            "epoch 612 : loss 0.0454 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.38s/it]\n",
            "epoch 613 : loss 0.0453 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.37s/it]\n",
            "epoch 614 : loss 0.0455 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.40s/it]\n",
            "epoch 615 : loss 0.0451 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.39s/it]\n",
            "epoch 616 : loss 0.0454 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.40s/it]\n",
            "epoch 617 : loss 0.0454 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.39s/it]\n",
            "epoch 618 : loss 0.0453 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.40s/it]\n",
            "epoch 619 : loss 0.0452 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.38s/it]\n",
            "epoch 620 : loss 0.0455 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.40s/it]\n",
            "epoch 621 : loss 0.0451 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.37s/it]\n",
            "epoch 622 : loss 0.0454 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.38s/it]\n",
            "epoch 623 : loss 0.0453 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.38s/it]\n",
            "epoch 624 : loss 0.0456 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.39s/it]\n",
            "epoch 625 : loss 0.0453 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.37s/it]\n",
            "epoch 626 : loss 0.0453 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.40s/it]\n",
            "epoch 627 : loss 0.0451 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.38s/it]\n",
            "epoch 628 : loss 0.0454 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.40s/it]\n",
            "epoch 629 : loss 0.0453 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.38s/it]\n",
            "epoch 630 : loss 0.0451 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.37s/it]\n",
            "epoch 631 : loss 0.0453 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.36s/it]\n",
            "epoch 632 : loss 0.0455 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.38s/it]\n",
            "epoch 633 : loss 0.0450 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.40s/it]\n",
            "epoch 634 : loss 0.0450 : [0.0005]\n",
            "100% 37/37 [00:52<00:00,  1.41s/it]\n",
            "epoch 635 : loss 0.0450 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.40s/it]\n",
            "epoch 636 : loss 0.0451 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.38s/it]\n",
            "epoch 637 : loss 0.0451 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.40s/it]\n",
            "epoch 638 : loss 0.0449 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.39s/it]\n",
            "epoch 639 : loss 0.0451 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.37s/it]\n",
            "epoch 640 : loss 0.0453 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.36s/it]\n",
            "epoch 641 : loss 0.0452 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.38s/it]\n",
            "epoch 642 : loss 0.0450 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.37s/it]\n",
            "epoch 643 : loss 0.0451 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.38s/it]\n",
            "epoch 644 : loss 0.0455 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.37s/it]\n",
            "epoch 645 : loss 0.0456 : [0.0005]\n",
            "100% 37/37 [00:49<00:00,  1.35s/it]\n",
            "epoch 646 : loss 0.0455 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.39s/it]\n",
            "epoch 647 : loss 0.0448 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.35s/it]\n",
            "epoch 648 : loss 0.0451 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.37s/it]\n",
            "epoch 649 : loss 0.0450 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.37s/it]\n",
            "epoch 650 : loss 0.0448 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.36s/it]\n",
            "epoch 651 : loss 0.0450 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.37s/it]\n",
            "epoch 652 : loss 0.0450 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.37s/it]\n",
            "epoch 653 : loss 0.0453 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.37s/it]\n",
            "epoch 654 : loss 0.0449 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.35s/it]\n",
            "epoch 655 : loss 0.0451 : [0.0005]\n",
            "100% 37/37 [00:49<00:00,  1.35s/it]\n",
            "epoch 656 : loss 0.0455 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.38s/it]\n",
            "epoch 657 : loss 0.0450 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.37s/it]\n",
            "epoch 658 : loss 0.0451 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.37s/it]\n",
            "epoch 659 : loss 0.0450 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.38s/it]\n",
            "epoch 660 : loss 0.0448 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.39s/it]\n",
            "epoch 661 : loss 0.0448 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.36s/it]\n",
            "epoch 662 : loss 0.0451 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.39s/it]\n",
            "epoch 663 : loss 0.0449 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.37s/it]\n",
            "epoch 664 : loss 0.0450 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.36s/it]\n",
            "epoch 665 : loss 0.0450 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.38s/it]\n",
            "epoch 666 : loss 0.0450 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.36s/it]\n",
            "epoch 667 : loss 0.0450 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.36s/it]\n",
            "epoch 668 : loss 0.0450 : [0.0005]\n",
            "100% 37/37 [00:51<00:00,  1.39s/it]\n",
            "epoch 669 : loss 0.0445 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.38s/it]\n",
            "epoch 670 : loss 0.0448 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.36s/it]\n",
            "epoch 671 : loss 0.0450 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.37s/it]\n",
            "epoch 672 : loss 0.0449 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.36s/it]\n",
            "epoch 673 : loss 0.0450 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.36s/it]\n",
            "epoch 674 : loss 0.0449 : [0.0005]\n",
            "100% 37/37 [00:48<00:00,  1.31s/it]\n",
            "epoch 675 : loss 0.0455 : [0.0005]\n",
            " 11% 4/37 [00:04<00:37,  1.14s/it]Saved checkpoint: model-25000\n",
            "100% 37/37 [00:50<00:00,  1.35s/it]\n",
            "epoch 676 : loss 0.0451 : [0.0005]\n",
            "100% 37/37 [00:49<00:00,  1.35s/it]\n",
            "epoch 677 : loss 0.0450 : [0.0005]\n",
            "100% 37/37 [00:50<00:00,  1.36s/it]\n",
            "epoch 678 : loss 0.0449 : [0.0005]\n",
            "  0% 0/37 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "!python train.py --resume afrza/model-20000.pt afrza afrZA/metadata.csv datasets/afrZA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUv2C2Z5M-jR"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xF90RShFMt0C"
      },
      "outputs": [],
      "source": [
        "!tensorboard --logdir=tensorboard/ljspeech/events.out.tfevents.1660108560.ff3d00cb5098.657.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2ThNb31jhZV",
        "outputId": "2623e160-9d1d-4c09-9b41-0a180c5a4b7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading checkpoint from /content/Tacotron/tensorboard/ljspeech/events.out.tfevents.1660108560.ff3d00cb5098.657.0\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 191, in <module>\n",
            "    train_model(args)\n",
            "  File \"train.py\", line 92, in train_model\n",
            "    load_path=args.resume,\n",
            "  File \"train.py\", line 41, in load_checkpoint\n",
            "    checkpoint = torch.load(load_path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 713, in load\n",
            "    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 920, in _legacy_load\n",
            "    magic_number = pickle_module.load(f, **pickle_load_args)\n",
            "_pickle.UnpicklingError: invalid load key, '\\x18'.\n"
          ]
        }
      ],
      "source": [
        "!python train.py --resume tensorboard/ljspeech/events.out.tfevents.1660108560.ff3d00cb5098.657.0 ljspeech LJSpeech-1.1/metadata.csv datasets/LJSpeech-1.1"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "PantoffelTraining.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}